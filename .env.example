# LLM Provider Configuration
# Choose between "openai" or "ollama"
# LLM_PROVIDER=openai

# OpenAI Configuration (required if using OpenAI provider)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_api_key_here

# Optional: Override the LLM model
# For OpenAI: openai:gpt-4, openai:gpt-4-turbo, openai:gpt-3.5-turbo
# For Ollama: ollama:llama3.2, ollama:mistral, ollama:qwen2.5
# LLM_MODEL=openai:gpt-4

# Ollama Configuration (required if using Ollama provider)
# Base URL for Ollama server (default: http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434

# Optional: Other environment variables
# NVDA_LOG_PATH=C:\Users\YourUser\AppData\Local\Temp\nvda.log
